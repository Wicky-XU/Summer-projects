"""
COVID-19 è‚ºéƒ¨CTå›¾åƒåˆ†ç±»é¡¹ç›® - æ¨¡å‹æ„å»ºå’Œè®­ç»ƒæ¨¡å—
===============================================

è´Ÿè´£æ¨¡å‹æ¶æ„æ„å»ºã€è®­ç»ƒé…ç½®ã€å›è°ƒè®¾ç½®å’Œè®­ç»ƒæ‰§è¡Œç­‰åŠŸèƒ½
åŸºäºnotebookä¸­çš„æ¨¡å‹ç›¸å…³ä»£ç é‡æ„è€Œæˆ

"""

import os
import time
import pickle
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional

import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras.layers import *
from tensorflow.keras.models import Sequential, Model, load_model
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import (
    EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, 
    Callback, CSVLogger
)

from config import get_config


class GPUManager:
    """GPUç®¡ç†å™¨"""
    
    @staticmethod
    def setup_gpu() -> bool:
        """
        é…ç½®GPUè®¾ç½®ä»¥è·å¾—æœ€ä½³æ€§èƒ½
        
        Returns:
            bool: GPUæ˜¯å¦å¯ç”¨å¹¶é…ç½®æˆåŠŸ
        """
        gpus = tf.config.experimental.list_physical_devices('GPU')
        if gpus:
            try:
                # å¯ç”¨å†…å­˜å¢é•¿ä»¥é¿å…å ç”¨æ‰€æœ‰GPUå†…å­˜
                for gpu in gpus:
                    tf.config.experimental.set_memory_growth(gpu, True)
                print(f"âœ… GPUé…ç½®å®Œæˆï¼Œå‘ç° {len(gpus)} ä¸ªGPU")
                
                # æ˜¾ç¤ºGPUä¿¡æ¯
                for i, gpu in enumerate(gpus):
                    print(f"  GPU {i}: {gpu.name}")
                
                return True
            except RuntimeError as e:
                print(f"âŒ GPUé…ç½®é”™è¯¯: {e}")
                return False
        else:
            print("âš ï¸ æœªå‘ç°GPUï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")
            return False
    
    @staticmethod
    def get_gpu_memory_info() -> Dict[str, Any]:
        """è·å–GPUå†…å­˜ä¿¡æ¯"""
        try:
            gpus = tf.config.experimental.list_physical_devices('GPU')
            if gpus:
                return {
                    "gpu_count": len(gpus),
                    "gpu_available": True,
                    "gpu_names": [gpu.name for gpu in gpus]
                }
            else:
                return {"gpu_available": False, "gpu_count": 0}
        except Exception as e:
            return {"gpu_available": False, "error": str(e)}


class ModelBuilder:
    """æ¨¡å‹æ„å»ºå™¨"""
    
    def __init__(self, config=None):
        self.config = config or get_config()
    
    def create_model(self, version: str = None) -> tf.keras.Model:
        """
        æ ¹æ®ç‰ˆæœ¬åˆ›å»ºæ¨¡å‹
        
        Args:
            version: æ¨¡å‹ç‰ˆæœ¬ ("10_epochs" æˆ– "50_epochs")
            
        Returns:
            ç¼–è¯‘å¥½çš„Kerasæ¨¡å‹
        """
        if version is None:
            version = self.config.CURRENT_VERSION
        
        # è·å–æ¶æ„é…ç½®
        arch_config = self.config.get_model_architecture_config()
        
        if version == "50_epochs" or arch_config.get("metrics") == ['accuracy', 'precision', 'recall']:
            return self._create_enhanced_model(arch_config)
        else:
            return self._create_standard_model(arch_config)
    
    def _create_standard_model(self, arch_config: Dict[str, Any]) -> tf.keras.Model:
        """
        åˆ›å»ºæ ‡å‡†VGG16æ¨¡å‹ï¼ˆ10è½®ç‰ˆæœ¬ï¼‰
        
        Args:
            arch_config: æ¶æ„é…ç½®
            
        Returns:
            ç¼–è¯‘å¥½çš„æ¨¡å‹
        """
        print("åˆ›å»ºæ ‡å‡†VGG16æ¨¡å‹æ¶æ„...")
        
        # åŠ è½½é¢„è®­ç»ƒVGG16æ¨¡å‹
        base_model = VGG16(
            weights='imagenet',
            include_top=False,
            input_shape=self.config.INPUT_SHAPE
        )
        
        # åˆ›å»ºè‡ªå®šä¹‰åˆ†ç±»å™¨
        model = Sequential([
            base_model,
            GlobalAveragePooling2D(),
            Dropout(arch_config["dropout_rate"]),
            Dense(arch_config["dense_units"][0], activation='relu'),
            BatchNormalization(),
            Dropout(self.config.DENSE_DROPOUT_RATE),
            Dense(1, activation='sigmoid')  # äºŒåˆ†ç±»
        ])
        
        # å†»ç»“é¢„è®­ç»ƒå±‚
        base_model.trainable = False
        
        # ç¼–è¯‘æ¨¡å‹
        model.compile(
            optimizer=Adam(learning_rate=self.config.LEARNING_RATE),
            loss='binary_crossentropy',
            metrics=arch_config["metrics"]
        )
        
        print("âœ… æ ‡å‡†VGG16æ¨¡å‹åˆ›å»ºå®Œæˆ")
        return model
    
    def _create_enhanced_model(self, arch_config: Dict[str, Any]) -> tf.keras.Model:
        """
        åˆ›å»ºå¢å¼ºVGG16æ¨¡å‹ï¼ˆ50è½®ç‰ˆæœ¬ï¼‰
        
        Args:
            arch_config: æ¶æ„é…ç½®
            
        Returns:
            ç¼–è¯‘å¥½çš„æ¨¡å‹
        """
        print("åˆ›å»ºå¢å¼ºVGG16æ¨¡å‹æ¶æ„...")
        
        # åŠ è½½é¢„è®­ç»ƒVGG16æ¨¡å‹
        base_model = VGG16(
            weights='imagenet',
            include_top=False,
            input_shape=self.config.INPUT_SHAPE
        )
        
        # åˆ›å»ºå¢å¼ºçš„è‡ªå®šä¹‰åˆ†ç±»å™¨
        x = base_model.output
        x = GlobalAveragePooling2D()(x)
        x = Dropout(arch_config["dropout_rate"])(x)
        
        # å¤šå±‚Denseç½‘ç»œ
        dense_units = arch_config["dense_units"]
        dropout_rates = arch_config["dropout_rates"]
        
        for i, (units, dropout) in enumerate(zip(dense_units, dropout_rates)):
            x = Dense(units, activation='relu', name=f'dense_{i+1}')(x)
            x = BatchNormalization(name=f'bn_{i+1}')(x)
            x = Dropout(dropout, name=f'dropout_{i+1}')(x)
        
        # è¾“å‡ºå±‚
        predictions = Dense(1, activation='sigmoid', name='predictions')(x)
        
        # åˆ›å»ºæ¨¡å‹
        model = Model(inputs=base_model.input, outputs=predictions)
        
        # å†»ç»“é¢„è®­ç»ƒå±‚
        base_model.trainable = False
        
        # ç¼–è¯‘æ¨¡å‹
        model.compile(
            optimizer=Adam(learning_rate=self.config.LEARNING_RATE),
            loss='binary_crossentropy',
            metrics=arch_config["metrics"]
        )
        
        print("âœ… å¢å¼ºVGG16æ¨¡å‹åˆ›å»ºå®Œæˆ")
        return model
    
    def create_fine_tuned_model(self, base_model_path: str, 
                              unfreeze_layers: int = 4) -> tf.keras.Model:
        """
        åˆ›å»ºå¾®è°ƒæ¨¡å‹
        
        Args:
            base_model_path: åŸºç¡€æ¨¡å‹è·¯å¾„
            unfreeze_layers: è§£å†»çš„é¡¶å±‚æ•°é‡
            
        Returns:
            å¾®è°ƒåçš„æ¨¡å‹
        """
        print(f"ä» {base_model_path} åŠ è½½æ¨¡å‹è¿›è¡Œå¾®è°ƒ...")
        
        # åŠ è½½åŸºç¡€æ¨¡å‹
        model = load_model(base_model_path)
        
        # è·å–VGG16åŸºç¡€æ¨¡å‹
        base_model = model.layers[0]  # VGG16åŸºç¡€æ¨¡å‹
        base_model.trainable = True
        
        # å†»ç»“é™¤é¡¶å±‚å¤–çš„æ‰€æœ‰å±‚
        for layer in base_model.layers[:-unfreeze_layers]:
            layer.trainable = False
        
        # ä½¿ç”¨æ›´ä½çš„å­¦ä¹ ç‡è¿›è¡Œå¾®è°ƒ
        model.compile(
            optimizer=Adam(learning_rate=self.config.LEARNING_RATE / 10),
            loss='binary_crossentropy',
            metrics=['accuracy', 'precision', 'recall']
        )
        
        print(f"âœ… å¾®è°ƒæ¨¡å‹åˆ›å»ºå®Œæˆï¼Œè§£å†»äº†é¡¶éƒ¨ {unfreeze_layers} å±‚")
        return model
    
    @staticmethod
    def print_model_summary(model: tf.keras.Model, version: str = "current") -> None:
        """
        æ‰“å°è¯¦ç»†çš„æ¨¡å‹æ‘˜è¦
        
        Args:
            model: Kerasæ¨¡å‹
            version: ç‰ˆæœ¬æ ‡è¯†
        """
        print("\n" + "="*70)
        print(f"æ¨¡å‹æ¶æ„æ‘˜è¦ - {version.upper()} ç‰ˆæœ¬")
        print("="*70)
        
        # æ˜¾ç¤ºæ¨¡å‹ç»“æ„
        model.summary()
        
        # è®¡ç®—å‚æ•°ç»Ÿè®¡
        trainable_params = sum([np.prod(v.get_shape().as_list()) 
                              for v in model.trainable_variables])
        non_trainable_params = sum([np.prod(v.get_shape().as_list()) 
                                  for v in model.non_trainable_variables])
        total_params = trainable_params + non_trainable_params
        
        print(f"\nå‚æ•°ç»Ÿè®¡:")
        print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        print(f"  ä¸å¯è®­ç»ƒå‚æ•°: {non_trainable_params:,}")
        print(f"  æ€»å‚æ•°: {total_params:,}")
        
        # æ˜¾ç¤ºå†…å­˜ä¼°è®¡
        memory_mb = (total_params * 4) / (1024 * 1024)  # å‡è®¾float32
        print(f"  ä¼°è®¡å†…å­˜ä½¿ç”¨: {memory_mb:.1f} MB")
        
        # æ˜¾ç¤ºæ¨¡å‹é…ç½®
        print(f"\næ¨¡å‹é…ç½®:")
        print(f"  è¾“å…¥å½¢çŠ¶: {model.input_shape}")
        print(f"  è¾“å‡ºå½¢çŠ¶: {model.output_shape}")
        print(f"  å±‚æ•°: {len(model.layers)}")
        
        print("="*70)


class TrainingCallbacks:
    """è®­ç»ƒå›è°ƒç®¡ç†å™¨"""
    
    def __init__(self, config=None):
        self.config = config or get_config()
    
    def create_callbacks(self, version: str = None, 
                        save_path: str = None) -> List[Callback]:
        """
        åˆ›å»ºè®­ç»ƒå›è°ƒåˆ—è¡¨
        
        Args:
            version: ç‰ˆæœ¬åç§°
            save_path: æ¨¡å‹ä¿å­˜è·¯å¾„
            
        Returns:
            å›è°ƒå‡½æ•°åˆ—è¡¨
        """
        if version is None:
            version = self.config.CURRENT_VERSION
        
        if save_path is None:
            paths = self.config.get_file_paths(version)
            save_path = str(paths["best_model"])
        
        # è·å–å›è°ƒé…ç½®
        callback_config = self.config.get_callbacks_config()
        
        callbacks = []
        
        # æ—©åœå›è°ƒ
        early_stopping = EarlyStopping(
            **callback_config["early_stopping"]
        )
        callbacks.append(early_stopping)
        
        # æ¨¡å‹æ£€æŸ¥ç‚¹
        model_checkpoint = ModelCheckpoint(
            filepath=save_path,
            save_weights_only=False,
            **callback_config["model_checkpoint"]
        )
        callbacks.append(model_checkpoint)
        
        # å­¦ä¹ ç‡è°ƒåº¦
        reduce_lr = ReduceLROnPlateau(
            **callback_config["reduce_lr"]
        )
        callbacks.append(reduce_lr)
        
        # CSVæ—¥å¿—è®°å½•
        log_path = self.config.LOGS_PATH / f"training_{version}.csv"
        csv_logger = CSVLogger(str(log_path))
        callbacks.append(csv_logger)
        
        # è¯¦ç»†çš„è®­ç»ƒç›‘æ§å›è°ƒ
        verbose_callback = self._create_verbose_callback(version)
        callbacks.append(verbose_callback)
        
        print(f"åˆ›å»ºäº† {len(callbacks)} ä¸ªè®­ç»ƒå›è°ƒ:")
        print("- æ—©åœ (EarlyStopping)")
        print("- æ¨¡å‹æ£€æŸ¥ç‚¹ (ModelCheckpoint)")
        print("- å­¦ä¹ ç‡è°ƒåº¦ (ReduceLROnPlateau)")
        print("- CSVæ—¥å¿—è®°å½• (CSVLogger)")
        print("- è¯¦ç»†ç›‘æ§ (VerboseCallback)")
        
        return callbacks
    
    def _create_verbose_callback(self, version: str) -> Callback:
        """åˆ›å»ºè¯¦ç»†çš„è®­ç»ƒç›‘æ§å›è°ƒ"""
        
        class EnhancedVerboseCallback(Callback):
            def __init__(self, version, num_epochs):
                super().__init__()
                self.version = version
                self.num_epochs = num_epochs
                self.epoch_start_time = None
                self.training_start_time = time.time()
            
            def on_train_begin(self, logs=None):
                print(f"\nğŸš€ å¼€å§‹ {self.version} è®­ç»ƒä¼šè¯")
                print(f"ç›®æ ‡è½®æ•°: {self.num_epochs}")
                print("="*50)
            
            def on_epoch_begin(self, epoch, logs=None):
                self.epoch_start_time = time.time()
                print(f"\n--- è½®æ¬¡ {epoch + 1}/{self.num_epochs} ---")
            
            def on_epoch_end(self, epoch, logs=None):
                epoch_time = time.time() - self.epoch_start_time
                total_time = time.time() - self.training_start_time
                
                print(f"è½®æ¬¡ {epoch + 1}/{self.num_epochs} å®Œæˆ (ç”¨æ—¶ {epoch_time:.1f}s)")
                print(f"  è®­ç»ƒ   - æŸå¤±: {logs['loss']:.4f}, å‡†ç¡®ç‡: {logs['accuracy']:.4f}")
                print(f"  éªŒè¯   - æŸå¤±: {logs['val_loss']:.4f}, å‡†ç¡®ç‡: {logs['val_accuracy']:.4f}")
                
                # æ˜¾ç¤ºé¢å¤–æŒ‡æ ‡ï¼ˆå¦‚æœæœ‰ï¼‰
                if 'precision' in logs:
                    print(f"  ç²¾ç¡®åº¦: {logs.get('precision', 0):.4f}, å¬å›ç‡: {logs.get('recall', 0):.4f}")
                
                # è¿›åº¦æŒ‡ç¤º
                progress = (epoch + 1) / self.num_epochs * 100
                eta = (total_time / (epoch + 1)) * (self.num_epochs - epoch - 1)
                print(f"  è¿›åº¦: {progress:.1f}% | å‰©ä½™æ—¶é—´: {eta/60:.1f}åˆ†é’Ÿ")
                
                # è¿‡æ‹Ÿåˆæ£€æµ‹
                if epoch > 2:  # è‡³å°‘è®­ç»ƒ3è½®åæ‰æ£€æµ‹
                    acc_gap = logs['accuracy'] - logs['val_accuracy']
                    if acc_gap > 0.15:
                        print(f"  âš ï¸ å¯èƒ½è¿‡æ‹Ÿåˆ (å‡†ç¡®ç‡å·®å¼‚: {acc_gap:.3f})")
                    elif acc_gap < -0.05:
                        print(f"  ğŸ“ˆ éªŒè¯è¡¨ç°æ›´å¥½ (å·®å¼‚: {acc_gap:.3f})")
            
            def on_train_end(self, logs=None):
                total_time = time.time() - self.training_start_time
                print(f"\nâœ… {self.version} è®­ç»ƒå®Œæˆ!")
                print(f"æ€»è®­ç»ƒæ—¶é—´: {total_time/60:.1f}åˆ†é’Ÿ")
        
        return EnhancedVerboseCallback(version, self.config.NUM_EPOCHS)


class ModelTrainer:
    """æ¨¡å‹è®­ç»ƒå™¨"""
    
    def __init__(self, config=None):
        self.config = config or get_config()
        self.model = None
        self.history = None
        self.callbacks_manager = TrainingCallbacks(self.config)
    
    def train_model(self, model: tf.keras.Model, 
                   train_generator, validation_generator,
                   version: str = None) -> tf.keras.callbacks.History:
        """
        è®­ç»ƒæ¨¡å‹
        
        Args:
            model: è¦è®­ç»ƒçš„æ¨¡å‹
            train_generator: è®­ç»ƒæ•°æ®ç”Ÿæˆå™¨
            validation_generator: éªŒè¯æ•°æ®ç”Ÿæˆå™¨
            version: ç‰ˆæœ¬åç§°
            
        Returns:
            è®­ç»ƒå†å²
        """
        if version is None:
            version = self.config.CURRENT_VERSION
        
        self.model = model
        
        print(f"\nğŸš€ å¼€å§‹ {version} æ¨¡å‹è®­ç»ƒ")
        print("="*60)
        
        # åˆ›å»ºå›è°ƒ
        callbacks = self.callbacks_manager.create_callbacks(version)
        
        # è®¡ç®—è®­ç»ƒæ­¥æ•°
        steps_per_epoch = train_generator.samples // self.config.BATCH_SIZE
        validation_steps = validation_generator.samples // self.config.BATCH_SIZE
        
        print(f"\nè®­ç»ƒé…ç½®:")
        print(f"- æ‰¹æ¬¡å¤§å°: {self.config.BATCH_SIZE}")
        print(f"- è®­ç»ƒè½®æ•°: {self.config.NUM_EPOCHS}")
        print(f"- æ¯è½®æ­¥æ•°: {steps_per_epoch}")
        print(f"- éªŒè¯æ­¥æ•°: {validation_steps}")
        print(f"- å­¦ä¹ ç‡: {self.config.LEARNING_RATE}")
        print(f"- ä¼˜åŒ–å™¨: Adam")
        
        # å¼€å§‹è®­ç»ƒ
        try:
            start_time = time.time()
            
            self.history = model.fit(
                train_generator,
                steps_per_epoch=steps_per_epoch,
                epochs=self.config.NUM_EPOCHS,
                validation_data=validation_generator,
                validation_steps=validation_steps,
                callbacks=callbacks,
                verbose=1  # æ˜¾ç¤ºè¿›åº¦æ¡
            )
            
            training_time = time.time() - start_time
            print(f"\nâœ… è®­ç»ƒå®Œæˆ! æ€»ç”¨æ—¶: {training_time/60:.1f}åˆ†é’Ÿ")
            
        except KeyboardInterrupt:
            print("\nâ¹ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
            return None
        except Exception as e:
            print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            raise e
        
        return self.history
    
    def save_model_and_history(self, version: str = None) -> Dict[str, str]:
        """
        ä¿å­˜æ¨¡å‹å’Œè®­ç»ƒå†å²
        
        Args:
            version: ç‰ˆæœ¬åç§°
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„å­—å…¸
        """
        if version is None:
            version = self.config.CURRENT_VERSION
        
        if self.model is None or self.history is None:
            raise ValueError("æ²¡æœ‰å¯ä¿å­˜çš„æ¨¡å‹æˆ–å†å²è®°å½•")
        
        paths = self.config.get_file_paths(version)
        saved_files = {}
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        model_path = paths["model"]
        self.model.save(str(model_path))
        saved_files["model"] = str(model_path)
        print(f"âœ… æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: {model_path}")
        
        # ä¿å­˜è®­ç»ƒå†å²
        history_data = {
            'history': self.history.history,
            'config': {
                'version': version,
                'epochs': self.config.NUM_EPOCHS,
                'batch_size': self.config.BATCH_SIZE,
                'learning_rate': self.config.LEARNING_RATE,
                'architecture': self.config.ARCHITECTURE_TYPE,
                'augmentation': self.config.CURRENT_AUGMENTATION
            },
            'training_info': {
                'total_epochs': len(self.history.history['accuracy']),
                'final_train_acc': self.history.history['accuracy'][-1],
                'final_val_acc': self.history.history['val_accuracy'][-1],
                'best_val_acc': max(self.history.history['val_accuracy']),
                'best_val_acc_epoch': np.argmax(self.history.history['val_accuracy']) + 1
            }
        }
        
        history_path = paths["history"]
        with open(history_path, 'wb') as f:
            pickle.dump(history_data, f)
        saved_files["history"] = str(history_path)
        print(f"âœ… è®­ç»ƒå†å²å·²ä¿å­˜: {history_path}")
        
        # ä¿å­˜æ¨¡å‹æ‘˜è¦
        summary_path = paths["summary"]
        summary_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write(f"COVID-19åˆ†ç±»æ¨¡å‹æ‘˜è¦ - {version} ç‰ˆæœ¬\n")
            f.write("="*50 + "\n\n")
            f.write(f"è®­ç»ƒå®Œæˆè½®æ•°: {len(self.history.history['accuracy'])}/{self.config.NUM_EPOCHS}\n")
            f.write(f"æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡: {self.history.history['accuracy'][-1]:.4f}\n")
            f.write(f"æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {self.history.history['val_accuracy'][-1]:.4f}\n")
            f.write(f"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {max(self.history.history['val_accuracy']):.4f}\n")
            f.write(f"æœ€ä½³å‡†ç¡®ç‡è½®æ¬¡: {np.argmax(self.history.history['val_accuracy']) + 1}\n")
            f.write(f"æ¨¡å‹æ¶æ„: {self.config.ARCHITECTURE_TYPE}\n")
            
            # è®¡ç®—å‚æ•°
            trainable_params = sum([np.prod(v.get_shape().as_list()) 
                                  for v in self.model.trainable_variables])
            total_params = sum([np.prod(v.get_shape().as_list()) 
                              for v in self.model.variables])
            f.write(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}\n")
            f.write(f"æ€»å‚æ•°: {total_params:,}\n")
        
        saved_files["summary"] = str(summary_path)
        print(f"âœ… æ¨¡å‹æ‘˜è¦å·²ä¿å­˜: {summary_path}")
        
        return saved_files
    
    def get_training_summary(self) -> Dict[str, Any]:
        """è·å–è®­ç»ƒæ‘˜è¦ä¿¡æ¯"""
        if self.history is None:
            return {}
        
        history = self.history.history
        
        return {
            "epochs_completed": len(history['accuracy']),
            "final_train_accuracy": history['accuracy'][-1],
            "final_val_accuracy": history['val_accuracy'][-1],
            "final_train_loss": history['loss'][-1],
            "final_val_loss": history['val_loss'][-1],
            "best_val_accuracy": max(history['val_accuracy']),
            "best_val_accuracy_epoch": np.argmax(history['val_accuracy']) + 1,
            "min_val_loss": min(history['val_loss']),
            "min_val_loss_epoch": np.argmin(history['val_loss']) + 1,
            "overfitting_score": history['accuracy'][-1] - history['val_accuracy'][-1]
        }


# ä¾¿æ·å‡½æ•°
def create_and_train_model(train_generator, validation_generator, 
                          version: str = None) -> Tuple[tf.keras.Model, tf.keras.callbacks.History]:
    """
    åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹çš„å®Œæ•´æµç¨‹
    
    Args:
        train_generator: è®­ç»ƒæ•°æ®ç”Ÿæˆå™¨
        validation_generator: éªŒè¯æ•°æ®ç”Ÿæˆå™¨
        version: ç‰ˆæœ¬åç§°
        
    Returns:
        (è®­ç»ƒå¥½çš„æ¨¡å‹, è®­ç»ƒå†å²)
    """
    config = get_config()
    if version:
        config.switch_version(version)
    
    # è®¾ç½®GPU
    GPUManager.setup_gpu()
    
    # åˆ›å»ºæ¨¡å‹
    builder = ModelBuilder(config)
    model = builder.create_model(version)
    builder.print_model_summary(model, version or config.CURRENT_VERSION)
    
    # è®­ç»ƒæ¨¡å‹
    trainer = ModelTrainer(config)
    history = trainer.train_model(model, train_generator, validation_generator, version)
    
    if history:
        # ä¿å­˜æ¨¡å‹å’Œå†å²
        saved_files = trainer.save_model_and_history(version)
        print(f"\nğŸ“ ä¿å­˜çš„æ–‡ä»¶: {list(saved_files.values())}")
        
        # æ‰“å°è®­ç»ƒæ‘˜è¦
        summary = trainer.get_training_summary()
        print(f"\nğŸ“Š è®­ç»ƒæ‘˜è¦:")
        for key, value in summary.items():
            print(f"  {key}: {value}")
    
    return model, history


if __name__ == "__main__":
    # æµ‹è¯•æ¨¡å‹æ„å»ºæ¨¡å—
    print("æµ‹è¯•æ¨¡å‹æ„å»ºæ¨¡å—...")
    
    # è®¾ç½®GPU
    print("\n1. è®¾ç½®GPU...")
    gpu_info = GPUManager.get_gpu_memory_info()
    print(f"GPUä¿¡æ¯: {gpu_info}")
    
    # åˆ›å»ºæ¨¡å‹æ„å»ºå™¨
    print("\n2. åˆ›å»ºæ¨¡å‹æ„å»ºå™¨...")
    builder = ModelBuilder()
    
    # æµ‹è¯•æ ‡å‡†æ¨¡å‹åˆ›å»º
    print("\n3. åˆ›å»ºæ ‡å‡†æ¨¡å‹...")
    model_10 = builder.create_model("10_epochs")
    builder.print_model_summary(model_10, "10_epochs")
    
    # æµ‹è¯•å¢å¼ºæ¨¡å‹åˆ›å»º
    print("\n4. åˆ›å»ºå¢å¼ºæ¨¡å‹...")
    model_50 = builder.create_model("50_epochs")
    builder.print_model_summary(model_50, "50_epochs")
    
    print("\nâœ… æ¨¡å‹æ„å»ºæ¨¡å—æµ‹è¯•å®Œæˆ!")