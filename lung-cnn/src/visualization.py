"""
COVID-19 è‚ºéƒ¨CTå›¾åƒåˆ†ç±»é¡¹ç›® - å¯è§†åŒ–å·¥å…·æ¨¡å—
==========================================

è´Ÿè´£è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–ã€ç»“æœåˆ†æå›¾è¡¨ã€æ¨¡å‹æ¯”è¾ƒç­‰åŠŸèƒ½
åŸºäºnotebookä¸­çš„å¯è§†åŒ–ä»£ç é‡æ„è€Œæˆ

"""

import os
import pickle
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional, Union

# è®¾ç½®matplotlibä¸­æ–‡æ”¯æŒå’Œæ ·å¼
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
plt.style.use('default')

from config import get_config


class TrainingVisualizer:
    """è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–å™¨"""
    
    def __init__(self, history=None, config=None):
        """
        åˆå§‹åŒ–å¯è§†åŒ–å™¨
        
        Args:
            history: è®­ç»ƒå†å²å¯¹è±¡æˆ–å­—å…¸
            config: é…ç½®å¯¹è±¡
        """
        self.config = config or get_config()
        self.history = history
        
        if isinstance(history, dict):
            # å¦‚æœæ˜¯å­—å…¸æ ¼å¼çš„å†å²è®°å½•
            self.history_dict = history
        elif hasattr(history, 'history'):
            # å¦‚æœæ˜¯Keras Historyå¯¹è±¡
            self.history_dict = history.history
        else:
            self.history_dict = None
    
    def load_history_from_file(self, history_path: str) -> bool:
        """
        ä»æ–‡ä»¶åŠ è½½è®­ç»ƒå†å²
        
        Args:
            history_path: å†å²æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: åŠ è½½æˆåŠŸè¿”å›True
        """
        try:
            with open(history_path, 'rb') as f:
                data = pickle.load(f)
            
            if isinstance(data, dict) and 'history' in data:
                self.history_dict = data['history']
            else:
                self.history_dict = data
            
            print(f"âœ… è®­ç»ƒå†å²åŠ è½½æˆåŠŸ: {history_path}")
            return True
            
        except Exception as e:
            print(f"âŒ åŠ è½½è®­ç»ƒå†å²å¤±è´¥: {str(e)}")
            return False
    
    def plot_training_history(self, save_path: str = None, 
                            title_suffix: str = "", figsize: Tuple[int, int] = (20, 15)) -> None:
        """
        ç»˜åˆ¶å®Œæ•´çš„è®­ç»ƒå†å²å›¾è¡¨
        
        Args:
            save_path: ä¿å­˜è·¯å¾„
            title_suffix: æ ‡é¢˜åç¼€
            figsize: å›¾å½¢å¤§å°
        """
        if not self.history_dict:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„è®­ç»ƒå†å²æ•°æ®")
            return
        
        # åˆ›å»ºç»¼åˆå›¾è¡¨
        fig = plt.figure(figsize=figsize)
        fig.suptitle(f'COVID-19 åˆ†ç±»æ¨¡å‹è®­ç»ƒç»“æœ {title_suffix}', fontsize=16, fontweight='bold')
        
        epochs_range = range(1, len(self.history_dict['accuracy']) + 1)
        
        # 1. å‡†ç¡®ç‡å›¾è¡¨
        plt.subplot(3, 3, 1)
        plt.plot(epochs_range, self.history_dict['accuracy'], 'b-', 
                label='è®­ç»ƒå‡†ç¡®ç‡', linewidth=2, marker='o', markersize=3)
        plt.plot(epochs_range, self.history_dict['val_accuracy'], 'r-', 
                label='éªŒè¯å‡†ç¡®ç‡', linewidth=2, marker='s', markersize=3)
        plt.title('æ¨¡å‹å‡†ç¡®ç‡', fontsize=14, fontweight='bold')
        plt.xlabel('è½®æ¬¡')
        plt.ylabel('å‡†ç¡®ç‡')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 2. æŸå¤±å›¾è¡¨
        plt.subplot(3, 3, 2)
        plt.plot(epochs_range, self.history_dict['loss'], 'b-', 
                label='è®­ç»ƒæŸå¤±', linewidth=2, marker='o', markersize=3)
        plt.plot(epochs_range, self.history_dict['val_loss'], 'r-', 
                label='éªŒè¯æŸå¤±', linewidth=2, marker='s', markersize=3)
        plt.title('æ¨¡å‹æŸå¤±', fontsize=14, fontweight='bold')
        plt.xlabel('è½®æ¬¡')
        plt.ylabel('æŸå¤±')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 3. ç²¾ç¡®åº¦å›¾è¡¨ï¼ˆå¦‚æœæœ‰ï¼‰
        if 'precision' in self.history_dict:
            plt.subplot(3, 3, 3)
            plt.plot(epochs_range, self.history_dict['precision'], 'g-', 
                    label='è®­ç»ƒç²¾ç¡®åº¦', linewidth=2, marker='o', markersize=3)
            if 'val_precision' in self.history_dict:
                plt.plot(epochs_range, self.history_dict['val_precision'], 'orange', 
                        label='éªŒè¯ç²¾ç¡®åº¦', linewidth=2, marker='s', markersize=3)
            plt.title('æ¨¡å‹ç²¾ç¡®åº¦', fontsize=14, fontweight='bold')
            plt.xlabel('è½®æ¬¡')
            plt.ylabel('ç²¾ç¡®åº¦')
            plt.legend()
            plt.grid(True, alpha=0.3)
        
        # 4. å¬å›ç‡å›¾è¡¨ï¼ˆå¦‚æœæœ‰ï¼‰
        if 'recall' in self.history_dict:
            plt.subplot(3, 3, 4)
            plt.plot(epochs_range, self.history_dict['recall'], 'purple', 
                    label='è®­ç»ƒå¬å›ç‡', linewidth=2, marker='o', markersize=3)
            if 'val_recall' in self.history_dict:
                plt.plot(epochs_range, self.history_dict['val_recall'], 'brown', 
                        label='éªŒè¯å¬å›ç‡', linewidth=2, marker='s', markersize=3)
            plt.title('æ¨¡å‹å¬å›ç‡', fontsize=14, fontweight='bold')
            plt.xlabel('è½®æ¬¡')
            plt.ylabel('å¬å›ç‡')
            plt.legend()
            plt.grid(True, alpha=0.3)
        
        # 5. å­¦ä¹ ç‡å›¾è¡¨ï¼ˆç®€åŒ–è¡¨ç¤ºï¼‰
        plt.subplot(3, 3, 5)
        # ç”±äºå®é™…LRå˜åŒ–éœ€è¦å›è°ƒè®°å½•ï¼Œè¿™é‡Œæ˜¾ç¤ºåˆå§‹å­¦ä¹ ç‡
        plt.axhline(y=self.config.LEARNING_RATE, color='k', linestyle='--', label='åˆå§‹å­¦ä¹ ç‡')
        plt.title('å­¦ä¹ ç‡è°ƒåº¦', fontsize=14, fontweight='bold')
        plt.xlabel('è½®æ¬¡')
        plt.ylabel('å­¦ä¹ ç‡')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.yscale('log')
        
        # 6. æœ€ç»ˆæ€§èƒ½å¯¹æ¯”
        plt.subplot(3, 3, 6)
        final_train_acc = self.history_dict['accuracy'][-1]
        final_val_acc = self.history_dict['val_accuracy'][-1]
        best_val_acc = max(self.history_dict['val_accuracy'])
        
        metrics = ['æœ€ç»ˆè®­ç»ƒ', 'æœ€ç»ˆéªŒè¯', 'æœ€ä½³éªŒè¯']
        values = [final_train_acc, final_val_acc, best_val_acc]
        colors = ['blue', 'red', 'green']
        
        bars = plt.bar(metrics, values, color=colors, alpha=0.7)
        plt.title('å‡†ç¡®ç‡å¯¹æ¯”', fontsize=14, fontweight='bold')
        plt.ylabel('å‡†ç¡®ç‡')
        plt.ylim(0, 1)
        
        for bar, value in zip(bars, values):
            plt.text(bar.get_x() + bar.get_width()/2, value + 0.01, 
                    f'{value:.4f}', ha='center', va='bottom', fontweight='bold')
        
        # 7. æŸå¤±å¯¹æ¯”
        plt.subplot(3, 3, 7)
        final_train_loss = self.history_dict['loss'][-1]
        final_val_loss = self.history_dict['val_loss'][-1]
        min_val_loss = min(self.history_dict['val_loss'])
        
        loss_metrics = ['æœ€ç»ˆè®­ç»ƒ', 'æœ€ç»ˆéªŒè¯', 'æœ€å°éªŒè¯']
        loss_values = [final_train_loss, final_val_loss, min_val_loss]
        
        bars = plt.bar(loss_metrics, loss_values, color=colors, alpha=0.7)
        plt.title('æŸå¤±å¯¹æ¯”', fontsize=14, fontweight='bold')
        plt.ylabel('æŸå¤±')
        
        for bar, value in zip(bars, loss_values):
            plt.text(bar.get_x() + bar.get_width()/2, value + max(loss_values) * 0.02, 
                    f'{value:.4f}', ha='center', va='bottom', fontweight='bold')
        
        # 8. å¹³æ»‘è¶‹åŠ¿å›¾
        plt.subplot(3, 3, 8)
        window_size = max(1, len(epochs_range) // 10)
        
        def moving_average(data, window_size):
            return [sum(data[max(0, i-window_size):i+1]) / min(i+1, window_size) 
                   for i in range(len(data))]
        
        smooth_train_acc = moving_average(self.history_dict['accuracy'], window_size)
        smooth_val_acc = moving_average(self.history_dict['val_accuracy'], window_size)
        
        plt.plot(epochs_range, smooth_train_acc, 'b-', label='å¹³æ»‘è®­ç»ƒå‡†ç¡®ç‡', linewidth=2)
        plt.plot(epochs_range, smooth_val_acc, 'r-', label='å¹³æ»‘éªŒè¯å‡†ç¡®ç‡', linewidth=2)
        plt.title('å¹³æ»‘å‡†ç¡®ç‡è¶‹åŠ¿', fontsize=14, fontweight='bold')
        plt.xlabel('è½®æ¬¡')
        plt.ylabel('å‡†ç¡®ç‡')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 9. è¿‡æ‹Ÿåˆåˆ†æ
        plt.subplot(3, 3, 9)
        acc_diff = [train - val for train, val in zip(
            self.history_dict['accuracy'], self.history_dict['val_accuracy'])]
        plt.plot(epochs_range, acc_diff, 'purple', linewidth=2, label='è®­ç»ƒ-éªŒè¯å‡†ç¡®ç‡å·®')
        plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)
        plt.axhline(y=0.1, color='red', linestyle=':', alpha=0.7, label='è¿‡æ‹Ÿåˆè­¦æˆ’çº¿')
        plt.title('è¿‡æ‹Ÿåˆåˆ†æ', fontsize=14, fontweight='bold')
        plt.xlabel('è½®æ¬¡')
        plt.ylabel('å‡†ç¡®ç‡å·®å¼‚')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… è®­ç»ƒå›¾è¡¨å·²ä¿å­˜: {save_path}")
        
        plt.show()
    
    def plot_metrics_comparison(self, save_path: str = None) -> None:
        """ç»˜åˆ¶æŒ‡æ ‡å¯¹æ¯”å›¾"""
        if not self.history_dict:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„è®­ç»ƒå†å²æ•°æ®")
            return
        
        # å‡†å¤‡æ•°æ®
        metrics_data = {}
        for key in self.history_dict:
            if not key.startswith('val_'):
                val_key = f'val_{key}'
                if val_key in self.history_dict:
                    metrics_data[key] = {
                        'train': self.history_dict[key][-1],
                        'val': self.history_dict[val_key][-1]
                    }
        
        if not metrics_data:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„æŒ‡æ ‡æ•°æ®")
            return
        
        # åˆ›å»ºå¯¹æ¯”å›¾
        fig, axes = plt.subplots(1, len(metrics_data), figsize=(5*len(metrics_data), 6))
        if len(metrics_data) == 1:
            axes = [axes]
        
        for i, (metric, values) in enumerate(metrics_data.items()):
            ax = axes[i]
            
            x = ['è®­ç»ƒ', 'éªŒè¯']
            y = [values['train'], values['val']]
            colors = ['skyblue', 'lightcoral']
            
            bars = ax.bar(x, y, color=colors, alpha=0.8)
            ax.set_title(f'{metric.title()}', fontsize=14, fontweight='bold')
            ax.set_ylabel(metric.title())
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, value in zip(bars, y):
                ax.text(bar.get_x() + bar.get_width()/2, value + max(y) * 0.01,
                       f'{value:.4f}', ha='center', va='bottom', fontweight='bold')
            
            # è®¾ç½®yè½´èŒƒå›´
            if metric == 'accuracy':
                ax.set_ylim(0, 1)
            elif metric == 'loss':
                ax.set_ylim(0, max(y) * 1.2)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… æŒ‡æ ‡å¯¹æ¯”å›¾å·²ä¿å­˜: {save_path}")
        
        plt.show()
    
    def get_training_summary(self) -> Dict[str, Any]:
        """è·å–è®­ç»ƒæ‘˜è¦ç»Ÿè®¡"""
        if not self.history_dict:
            return {}
        
        summary = {
            'epochs_completed': len(self.history_dict['accuracy']),
            'final_train_accuracy': self.history_dict['accuracy'][-1],
            'final_val_accuracy': self.history_dict['val_accuracy'][-1],
            'final_train_loss': self.history_dict['loss'][-1],
            'final_val_loss': self.history_dict['val_loss'][-1],
            'best_val_accuracy': max(self.history_dict['val_accuracy']),
            'best_val_accuracy_epoch': np.argmax(self.history_dict['val_accuracy']) + 1,
            'min_val_loss': min(self.history_dict['val_loss']),
            'min_val_loss_epoch': np.argmin(self.history_dict['val_loss']) + 1,
            'overfitting_score': self.history_dict['accuracy'][-1] - self.history_dict['val_accuracy'][-1]
        }
        
        # æ·»åŠ é¢å¤–æŒ‡æ ‡ï¼ˆå¦‚æœæœ‰ï¼‰
        if 'precision' in self.history_dict:
            summary['final_precision'] = self.history_dict['precision'][-1]
        if 'recall' in self.history_dict:
            summary['final_recall'] = self.history_dict['recall'][-1]
        
        return summary


class PredictionVisualizer:
    """é¢„æµ‹ç»“æœå¯è§†åŒ–å™¨"""
    
    def __init__(self, config=None):
        self.config = config or get_config()
    
    def plot_prediction_results(self, results: List[Dict[str, Any]], 
                              analysis: Dict[str, Any], save_path: str = None) -> None:
        """
        ç»˜åˆ¶é¢„æµ‹ç»“æœç»¼åˆå›¾è¡¨
        
        Args:
            results: é¢„æµ‹ç»“æœåˆ—è¡¨
            analysis: åˆ†æç»“æœ
            save_path: ä¿å­˜è·¯å¾„
        """
        if not results:
            print("âŒ æ²¡æœ‰é¢„æµ‹ç»“æœå¯è§†åŒ–")
            return
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('COVID-19 åˆ†ç±»é¢„æµ‹ç»“æœåˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. ç½®ä¿¡åº¦åˆ†å¸ƒç›´æ–¹å›¾
        confidences = [r['confidence'] for r in results]
        ax1.hist(confidences, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        ax1.axvline(np.mean(confidences), color='red', linestyle='--', 
                   label=f'å¹³å‡å€¼: {np.mean(confidences):.3f}')
        ax1.set_title('é¢„æµ‹ç½®ä¿¡åº¦åˆ†å¸ƒ', fontweight='bold')
        ax1.set_xlabel('ç½®ä¿¡åº¦')
        ax1.set_ylabel('é¢‘æ¬¡')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. ç±»åˆ«åˆ†å¸ƒé¥¼å›¾
        class_counts = analysis['class_distribution']
        labels = [f'{k.upper()}\n({v} å¼ å›¾åƒ)' for k, v in class_counts.items()]
        colors = ['lightcoral', 'lightblue']
        
        wedges, texts, autotexts = ax2.pie(class_counts.values(), labels=labels, 
                                          autopct='%1.1f%%', startangle=90, colors=colors)
        ax2.set_title('ç±»åˆ«åˆ†å¸ƒ', fontweight='bold')
        
        # 3. ç½®ä¿¡åº¦vsä¸ç¡®å®šæ€§æ•£ç‚¹å›¾
        confidences = [r['confidence'] for r in results]
        uncertainties = [r['uncertainty'] for r in results]
        colors_scatter = ['red' if r['prediction'] == 'yes' else 'blue' for r in results]
        
        ax3.scatter(confidences, uncertainties, c=colors_scatter, alpha=0.6, s=30)
        ax3.set_xlabel('ç½®ä¿¡åº¦')
        ax3.set_ylabel('ä¸ç¡®å®šæ€§')
        ax3.set_title('ç½®ä¿¡åº¦ vs ä¸ç¡®å®šæ€§', fontweight='bold')
        ax3.grid(True, alpha=0.3)
        
        # æ·»åŠ å›¾ä¾‹
        from matplotlib.patches import Patch
        legend_elements = [Patch(facecolor='red', label='COVID-19 é˜³æ€§'),
                          Patch(facecolor='blue', label='COVID-19 é˜´æ€§')]
        ax3.legend(handles=legend_elements)
        
        # 4. ç½®ä¿¡åº¦ç­‰çº§åˆ†å¸ƒ
        conf_levels = analysis['confidence_levels']
        level_names = ['æé«˜\n(>0.95)', 'é«˜\n(0.9-0.95)', 'ä¸­ç­‰\n(0.7-0.9)', 'ä½\n(<0.7)']
        level_counts = [conf_levels['very_high'], conf_levels['high'], 
                       conf_levels['medium'], conf_levels['low']]
        colors_bar = ['darkgreen', 'green', 'orange', 'red']
        
        bars = ax4.bar(level_names, level_counts, color=colors_bar, alpha=0.7)
        ax4.set_title('ç½®ä¿¡åº¦ç­‰çº§åˆ†å¸ƒ', fontweight='bold')
        ax4.set_ylabel('å›¾åƒæ•°é‡')
        
        for bar, count in zip(bars, level_counts):
            ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(level_counts) * 0.01,
                    str(count), ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… é¢„æµ‹ç»“æœå›¾è¡¨å·²ä¿å­˜: {save_path}")
        
        plt.show()
    
    def plot_confidence_analysis(self, results: List[Dict[str, Any]], 
                               save_path: str = None) -> None:
        """ç»˜åˆ¶è¯¦ç»†çš„ç½®ä¿¡åº¦åˆ†æå›¾"""
        if not results:
            return
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('ç½®ä¿¡åº¦è¯¦ç»†åˆ†æ', fontsize=16, fontweight='bold')
        
        # æŒ‰ç±»åˆ«åˆ†ç»„
        yes_results = [r for r in results if r['prediction'] == 'yes']
        no_results = [r for r in results if r['prediction'] == 'no']
        
        # 1. æŒ‰ç±»åˆ«çš„ç½®ä¿¡åº¦åˆ†å¸ƒ
        yes_conf = [r['confidence'] for r in yes_results]
        no_conf = [r['confidence'] for r in no_results]
        
        ax1.hist([yes_conf, no_conf], bins=15, alpha=0.7, 
                label=['COVID-19 é˜³æ€§', 'COVID-19 é˜´æ€§'], color=['red', 'blue'])
        ax1.set_title('æŒ‰ç±»åˆ«çš„ç½®ä¿¡åº¦åˆ†å¸ƒ')
        ax1.set_xlabel('ç½®ä¿¡åº¦')
        ax1.set_ylabel('é¢‘æ¬¡')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. ç½®ä¿¡åº¦ç®±çº¿å›¾
        conf_data = [yes_conf, no_conf]
        ax2.boxplot(conf_data, labels=['é˜³æ€§', 'é˜´æ€§'])
        ax2.set_title('ç½®ä¿¡åº¦ç®±çº¿å›¾å¯¹æ¯”')
        ax2.set_ylabel('ç½®ä¿¡åº¦')
        ax2.grid(True, alpha=0.3)
        
        # 3. ä¸ç¡®å®šæ€§åˆ†æ
        yes_unc = [r['uncertainty'] for r in yes_results]
        no_unc = [r['uncertainty'] for r in no_results]
        
        ax3.hist([yes_unc, no_unc], bins=15, alpha=0.7,
                label=['COVID-19 é˜³æ€§', 'COVID-19 é˜´æ€§'], color=['red', 'blue'])
        ax3.set_title('æŒ‰ç±»åˆ«çš„ä¸ç¡®å®šæ€§åˆ†å¸ƒ')
        ax3.set_xlabel('ä¸ç¡®å®šæ€§')
        ax3.set_ylabel('é¢‘æ¬¡')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # 4. åŸå§‹æ¦‚ç‡åˆ†å¸ƒ
        raw_probs = [r['raw_probability'] for r in results]
        ax4.hist(raw_probs, bins=20, alpha=0.7, color='green', edgecolor='black')
        ax4.axvline(0.5, color='red', linestyle='--', label='å†³ç­–è¾¹ç•Œ (0.5)')
        ax4.set_title('åŸå§‹é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ')
        ax4.set_xlabel('é¢„æµ‹æ¦‚ç‡')
        ax4.set_ylabel('é¢‘æ¬¡')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… ç½®ä¿¡åº¦åˆ†æå›¾å·²ä¿å­˜: {save_path}")
        
        plt.show()


class ModelComparator:
    """æ¨¡å‹æ¯”è¾ƒå™¨"""
    
    def __init__(self, config=None):
        self.config = config or get_config()
    
    def compare_training_histories(self, history_path_1: str, history_path_2: str,
                                 labels: List[str] = None, save_path: str = None) -> None:
        """
        æ¯”è¾ƒä¸¤ä¸ªæ¨¡å‹çš„è®­ç»ƒå†å²
        
        Args:
            history_path_1: ç¬¬ä¸€ä¸ªæ¨¡å‹çš„å†å²æ–‡ä»¶è·¯å¾„
            history_path_2: ç¬¬äºŒä¸ªæ¨¡å‹çš„å†å²æ–‡ä»¶è·¯å¾„
            labels: æ¨¡å‹æ ‡ç­¾åˆ—è¡¨
            save_path: ä¿å­˜è·¯å¾„
        """
        # åŠ è½½å†å²æ•°æ®
        try:
            with open(history_path_1, 'rb') as f:
                data1 = pickle.load(f)
            with open(history_path_2, 'rb') as f:
                data2 = pickle.load(f)
            
            hist1 = data1['history'] if isinstance(data1, dict) and 'history' in data1 else data1
            hist2 = data2['history'] if isinstance(data2, dict) and 'history' in data2 else data2
            
        except Exception as e:
            print(f"âŒ åŠ è½½å†å²æ–‡ä»¶å¤±è´¥: {str(e)}")
            return
        
        if labels is None:
            labels = ['10è½®è®­ç»ƒ', '50è½®è®­ç»ƒ']
        
        # åˆ›å»ºæ¯”è¾ƒå›¾è¡¨
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('æ¨¡å‹è®­ç»ƒå¯¹æ¯”åˆ†æ', fontsize=16, fontweight='bold')
        
        epochs1 = range(1, len(hist1['accuracy']) + 1)
        epochs2 = range(1, len(hist2['accuracy']) + 1)
        
        # 1. è®­ç»ƒå‡†ç¡®ç‡å¯¹æ¯”
        ax1.plot(epochs1, hist1['accuracy'], 'b-', label=f'{labels[0]} è®­ç»ƒ', linewidth=2)
        ax1.plot(epochs1, hist1['val_accuracy'], 'b--', label=f'{labels[0]} éªŒè¯', linewidth=2)
        ax1.plot(epochs2, hist2['accuracy'], 'r-', label=f'{labels[1]} è®­ç»ƒ', linewidth=2)
        ax1.plot(epochs2, hist2['val_accuracy'], 'r--', label=f'{labels[1]} éªŒè¯', linewidth=2)
        ax1.set_title('å‡†ç¡®ç‡å¯¹æ¯”')
        ax1.set_xlabel('è½®æ¬¡')
        ax1.set_ylabel('å‡†ç¡®ç‡')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. è®­ç»ƒæŸå¤±å¯¹æ¯”
        ax2.plot(epochs1, hist1['loss'], 'b-', label=f'{labels[0]} è®­ç»ƒ', linewidth=2)
        ax2.plot(epochs1, hist1['val_loss'], 'b--', label=f'{labels[0]} éªŒè¯', linewidth=2)
        ax2.plot(epochs2, hist2['loss'], 'r-', label=f'{labels[1]} è®­ç»ƒ', linewidth=2)
        ax2.plot(epochs2, hist2['val_loss'], 'r--', label=f'{labels[1]} éªŒè¯', linewidth=2)
        ax2.set_title('æŸå¤±å¯¹æ¯”')
        ax2.set_xlabel('è½®æ¬¡')
        ax2.set_ylabel('æŸå¤±')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. æœ€ç»ˆæ€§èƒ½å¯¹æ¯”
        final_metrics = {
            labels[0]: {
                'train_acc': hist1['accuracy'][-1],
                'val_acc': hist1['val_accuracy'][-1],
                'train_loss': hist1['loss'][-1],
                'val_loss': hist1['val_loss'][-1]
            },
            labels[1]: {
                'train_acc': hist2['accuracy'][-1],
                'val_acc': hist2['val_accuracy'][-1],
                'train_loss': hist2['loss'][-1],
                'val_loss': hist2['val_loss'][-1]
            }
        }
        
        # å‡†ç¡®ç‡å¯¹æ¯”æŸ±çŠ¶å›¾
        x_pos = np.arange(2)
        train_accs = [final_metrics[labels[0]]['train_acc'], final_metrics[labels[1]]['train_acc']]
        val_accs = [final_metrics[labels[0]]['val_acc'], final_metrics[labels[1]]['val_acc']]
        
        width = 0.35
        ax3.bar(x_pos - width/2, train_accs, width, label='è®­ç»ƒå‡†ç¡®ç‡', alpha=0.8)
        ax3.bar(x_pos + width/2, val_accs, width, label='éªŒè¯å‡†ç¡®ç‡', alpha=0.8)
        ax3.set_title('æœ€ç»ˆå‡†ç¡®ç‡å¯¹æ¯”')
        ax3.set_ylabel('å‡†ç¡®ç‡')
        ax3.set_xticks(x_pos)
        ax3.set_xticklabels(labels)
        ax3.legend()
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (train_acc, val_acc) in enumerate(zip(train_accs, val_accs)):
            ax3.text(i - width/2, train_acc + 0.01, f'{train_acc:.3f}', 
                    ha='center', va='bottom', fontweight='bold')
            ax3.text(i + width/2, val_acc + 0.01, f'{val_acc:.3f}', 
                    ha='center', va='bottom', fontweight='bold')
        
        # 4. æ”¶æ•›é€Ÿåº¦åˆ†æ
        # è®¡ç®—è¾¾åˆ°ç‰¹å®šå‡†ç¡®ç‡é˜ˆå€¼çš„è½®æ¬¡
        threshold = 0.8
        
        def find_convergence_epoch(accuracy_list, threshold):
            for i, acc in enumerate(accuracy_list):
                if acc >= threshold:
                    return i + 1
            return len(accuracy_list)
        
        conv1 = find_convergence_epoch(hist1['val_accuracy'], threshold)
        conv2 = find_convergence_epoch(hist2['val_accuracy'], threshold)
        
        convergence_data = [conv1, conv2]
        ax4.bar(labels, convergence_data, alpha=0.8, color=['blue', 'red'])
        ax4.set_title(f'æ”¶æ•›é€Ÿåº¦å¯¹æ¯” (è¾¾åˆ°{threshold}å‡†ç¡®ç‡)')
        ax4.set_ylabel('æ‰€éœ€è½®æ¬¡')
        
        for i, conv in enumerate(convergence_data):
            ax4.text(i, conv + max(convergence_data) * 0.01, str(conv), 
                    ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… æ¨¡å‹å¯¹æ¯”å›¾å·²ä¿å­˜: {save_path}")
        
        plt.show()
        
        # æ‰“å°è¯¦ç»†å¯¹æ¯”æŠ¥å‘Š
        self._print_comparison_report(final_metrics, labels)
    
    def _print_comparison_report(self, metrics: Dict[str, Dict], labels: List[str]) -> None:
        """æ‰“å°è¯¦ç»†çš„æ¨¡å‹å¯¹æ¯”æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("æ¨¡å‹æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š")
        print("="*60)
        
        for label in labels:
            print(f"\n{label}:")
            print(f"  æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡: {metrics[label]['train_acc']:.4f}")
            print(f"  æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {metrics[label]['val_acc']:.4f}")
            print(f"  æœ€ç»ˆè®­ç»ƒæŸå¤±: {metrics[label]['train_loss']:.4f}")
            print(f"  æœ€ç»ˆéªŒè¯æŸå¤±: {metrics[label]['val_loss']:.4f}")
            
            # è¿‡æ‹Ÿåˆåˆ†æ
            overfitting = metrics[label]['train_acc'] - metrics[label]['val_acc']
            print(f"  è¿‡æ‹Ÿåˆç¨‹åº¦: {overfitting:.4f}")
            
            if overfitting > 0.1:
                print("    âš ï¸ å­˜åœ¨è¿‡æ‹Ÿåˆ")
            elif overfitting < 0:
                print("    ğŸ“ˆ éªŒè¯æ€§èƒ½æ›´å¥½")
            else:
                print("    âœ… æ‹Ÿåˆè‰¯å¥½")
        
        # æ€§èƒ½å¯¹æ¯”
        print(f"\næ€§èƒ½å¯¹æ¯”:")
        val_acc_diff = metrics[labels[1]]['val_acc'] - metrics[labels[0]]['val_acc']
        val_loss_diff = metrics[labels[0]]['val_loss'] - metrics[labels[1]]['val_loss']
        
        print(f"éªŒè¯å‡†ç¡®ç‡å·®å¼‚: {val_acc_diff:+.4f} ({labels[1]} vs {labels[0]})")
        print(f"éªŒè¯æŸå¤±å·®å¼‚: {val_loss_diff:+.4f} ({labels[0]} vs {labels[1]})")
        
        if val_acc_diff > 0.02:
            print(f"âœ… {labels[1]} æ˜¾è‘—ä¼˜äº {labels[0]}")
        elif val_acc_diff < -0.02:
            print(f"âœ… {labels[0]} æ˜¾è‘—ä¼˜äº {labels[1]}")
        else:
            print("âš–ï¸ ä¸¤ä¸ªæ¨¡å‹æ€§èƒ½ç›¸è¿‘")
        
        print("="*60)


# ä¾¿æ·å‡½æ•°
def visualize_training_results(history_path: str, save_dir: str = None, 
                              version: str = None) -> None:
    """
    å¯è§†åŒ–è®­ç»ƒç»“æœçš„ä¾¿æ·å‡½æ•°
    
    Args:
        history_path: è®­ç»ƒå†å²æ–‡ä»¶è·¯å¾„
        save_dir: ä¿å­˜ç›®å½•
        version: ç‰ˆæœ¬æ ‡è¯†
    """
    config = get_config()
    
    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = TrainingVisualizer(config=config)
    
    # åŠ è½½å†å²
    if not visualizer.load_history_from_file(history_path):
        return
    
    # è®¾ç½®ä¿å­˜è·¯å¾„
    if save_dir and version:
        save_path = Path(save_dir) / f"training_results_{version}.png"
    else:
        save_path = None
    
    # ç»˜åˆ¶å›¾è¡¨
    title_suffix = f"- {version}" if version else ""
    visualizer.plot_training_history(str(save_path) if save_path else None, title_suffix)
    
    # æ‰“å°æ‘˜è¦
    summary = visualizer.get_training_summary()
    if summary:
        print(f"\nğŸ“Š {version or 'æ¨¡å‹'} è®­ç»ƒæ‘˜è¦:")
        for key, value in summary.items():
            print(f"  {key}: {value}")


def visualize_prediction_results(results: List[Dict], analysis: Dict, 
                                save_dir: str = None, version: str = None) -> None:
    """
    å¯è§†åŒ–é¢„æµ‹ç»“æœçš„ä¾¿æ·å‡½æ•°
    
    Args:
        results: é¢„æµ‹ç»“æœåˆ—è¡¨
        analysis: åˆ†æç»“æœ
        save_dir: ä¿å­˜ç›®å½•
        version: ç‰ˆæœ¬æ ‡è¯†
    """
    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = PredictionVisualizer()
    
    # è®¾ç½®ä¿å­˜è·¯å¾„
    if save_dir and version:
        save_path = Path(save_dir) / f"prediction_results_{version}.png"
        conf_path = Path(save_dir) / f"confidence_analysis_{version}.png"
    else:
        save_path = None
        conf_path = None
    
    # ç»˜åˆ¶å›¾è¡¨
    visualizer.plot_prediction_results(results, analysis, str(save_path) if save_path else None)
    visualizer.plot_confidence_analysis(results, str(conf_path) if conf_path else None)


if __name__ == "__main__":
    # æµ‹è¯•å¯è§†åŒ–æ¨¡å—
    print("æµ‹è¯•å¯è§†åŒ–æ¨¡å—...")
    
    config = get_config()
    
    # åˆ›å»ºæ¨¡æ‹Ÿè®­ç»ƒå†å²
    mock_history = {
        'accuracy': [0.6, 0.7, 0.8, 0.85, 0.9],
        'val_accuracy': [0.55, 0.65, 0.75, 0.8, 0.82],
        'loss': [0.8, 0.6, 0.4, 0.3, 0.2],
        'val_loss': [0.85, 0.7, 0.5, 0.4, 0.35]
    }
    
    # æµ‹è¯•è®­ç»ƒå¯è§†åŒ–
    print("\n1. æµ‹è¯•è®­ç»ƒå†å²å¯è§†åŒ–...")
    visualizer = TrainingVisualizer(mock_history, config)
    visualizer.plot_training_history(title_suffix="æµ‹è¯•ç‰ˆæœ¬")
    
    # æµ‹è¯•æ‘˜è¦
    summary = visualizer.get_training_summary()
    print(f"\nè®­ç»ƒæ‘˜è¦: {summary}")
    
    print("\nâœ… å¯è§†åŒ–æ¨¡å—æµ‹è¯•å®Œæˆ!")